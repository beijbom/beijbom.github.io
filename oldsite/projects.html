<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>Oscar Beijbom | UCSD</title>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        
        <!-- Stylesheets -->
        <link rel="stylesheet" href="css/reset.css" />
        <link rel="stylesheet" href="css/styles.css" />
        
        <style type="text/css">
            <!--
            .style1 {
                font-size: 36px
            }
        -->
            </style>
    </head>
    
    <body>
        
        <div id="wrapper" class="container_12 clearfix">
            
            <!-- Text Logo -->
            <h1 class="grid_4 style1" id="logo">Oscar Beijbom</h1>
            
            <!-- Navigation Menu -->
            <ul id="navigation" class="grid_8">
                <li><a href="press.html"><br />Press</a></li>
                <li><a href="projects.html"><br />Projects</a></li>
                <li><a href="index.html"><br />Home</a></li>
            </ul>
            
            <div class="hr grid_12 clearfix">&nbsp;</div>
			
            <div class="grid_12">
                <h4 class="page_title">Mapping the World's Ocean Floors</h4>
                <p><em>PhD Thesis Proposal Work, UCSD, 2009 - </em></p>
                <p>
                My PhD thesis work is on the general topic of extracting scientific information from images. Specifically, I focus on coral reef survey images, and take a holistic approach to solving this problem. As such, I have worked on color and texture descriptors; cost-sensitive multiclass machine learning methods; methods for interactive, and semi automated annotation; cost-effective sampling designs that utilize machine or crowd annotations; and new sensor technologies such as wide-field-of-view fluorescence cameras. Much of my research is made availible directly to the coral ecology community through our website, <a href="coralnet.ucsd.edu">CoralNet</a>. 
                </p>
                <p>
                <a name="coralnet"> </a>
                <a class="portfolio_item float " href="http://coralnet.ucsd.edu">
                    <span>CoralNet</span>
                    <img src="images/coralnet.jpg" alt="coralnet" width="200" height="200" class="img_right" />
                </a>
                <h6 class="">CoralNet</h6>
                <p>
                CoralNet is a repository and a resource for benthic images analysis. The site implements our <a href="http://vision.ucsd.edu/sites/default/files/automated_coral_annotation.pdf">method</a> from CVPR2012 and allow researchers, agencies, and private partners to rapidly annotate benthic survey images. The site also serves as a repository and collaboration platform for the scientific community. [<a href="http://coralnet.ucsd.edu">www</a>]
                </p>
                <p> CoralNet users include the <a href="http://www.catlinseaviewsurvey.com/">Caitlin Seaview Survey</a>, the <a href="http://www.aims.gov.au/">Australian Institute of Marine Science (AIMS) </a>, Washington State University, University of Washington, University of North Carolina, Scripps Institution of Oceanography, Colby College</a>, and <a href="http://stanford.sea.edu/">Stanford@Sea</a>. </p>
                <div class="hr dotted clearfix">&nbsp;</div>
                <a class="portfolio_item float " href="">
					<span>Guess Averse Losses</span>
                    <img src="images/guess_averse.jpg" alt="guess_averse" width="200" height="200" class="img_right" />
                </a>
                
                <h6 class="">Cost-Sensitive Multiclass Learning</h6>
                <p> Supervised machine learning algorithms are most commonly studied for cost-insensitive binary classification. In such scenario the algorithm learns to seperate between two equally costly (important) classes. However, in many practial sitautions, there are multiple classes, and in addition the misclassification costs may differ between the classes. For example, for <a href="http://www.image-net.org/">image classification tasks</a> the misclassification between a 'Mountain Gorilla' and a 'Western Lowland Gorilla' is less severe than, say a 'Giraffe' and 'Chair'. This leads to the more complicated scenario of cost-sensitive multiclass learning. In joint work with Steve Branson (CVPR 2013), we proposed a fast <a href="http://vision.ucsd.edu/sites/default/files/cvpr2013_efficient_0.pdf">structured Support Vector Machine (SVM) solver</a> capable of cost-sensitive multiclass learning. The solver is based on coordinate dual ascent and converges order of magnitudes faster than previous structured SVM solvers. In another paper (ICML 2014) I examined properties of loss functions for cost-sensitive multiclass learning together with Mohammad (Ehsan) Saberian, and showed that a surprisingly simple property, which we call <a href="http://vision.ucsd.edu/sites/default/files/guess_averse.pdf">guess-averse</a> has strong empirical imporatance.
                </p>

                
                <div class="hr dotted clearfix">&nbsp;</div>
                <a class="portfolio_item float " href="http://vision.ucsd.edu/content/moorea-labeled-corals">
					<span>MLC</span>
                    <img src="images/mlc.jpg" alt="coralnet" width="200" height="200" class="img_right" />
                </a>
                
                <h6 class="">Coral Annotation Benchmark Datasets</h6>
                <p>
                I have prepared two datasets containing expert-annotated coral reef survey images: <a href="http://vision.ucsd.edu/content/moorea-labeled-corals">Moorea Labeled Corals</a> and <a href="http://vision.ucsd.edu/content/pacific-labeled-corals">Pacific Labeled Corals</a>. These datasets provide unique oportunities for benchmarking computer vision methods for texture classification and segmentation as well as machine learning methods for transfer learning.
                </p>
                <p>
                The Moorea Labeled Corals dataset is a subset of the Moorea Coral Reef-Long Term Ecological Research (<a href="http://mcr.lternet.edu/">MCR-LTER</a>) dataset, packaged for Computer Vision research. It contains over 400,000 expert annotations across 2,055 coral reef survey images from the island of Moorea in French Polynesia. Each image has 200 expert random point annotations, indicating the substrate underneath each point. <a href="http://www.mdpi.com/2072-4292/5/4/1809">This</a> recent publication         performs a benchmark evaluation of various coral reef image analysis methods on Moorea Labeled Corals.
</p>

<p>
Pacific Labeled Corals is an aggregate dataset containing 2,318 coral reef survey images from four Pacific monitoring projects and contains 318,828 expert annotations. The images have all been annotated using a random point annotation tool by a coral reef expert. In addition, 200 images from each location have been cross-annotatoed by 6 experts, for a total of 7 sets of annotations for each image. </p>

</div>
            <div class="hr grid_12 clearfix">&nbsp;</div>
            
            <div class="grid_12">
                <h4 class="page_title">Counting Calories</a></h4>
                <p><em>Microsoft Research, Seattle, Washington, USA</em></p>
                <p>
                <a class="portfolio_item float " href="http://research.microsoft.com/menumatch/data/">
					<span>Menu-Match</span>
                    <img src="images/menu-match.jpg" alt="menu-match" width="200" height="150" class="img_right" />
                </a>
            The World Health Organization (WHO) predicts that overweight and obesity may soon replace more traditional public health concerns such as undernutrition and infectious diseases as the most significant cause of poor health. Logging food and calorie intake has been shown to facilitate weight management, but current food logging methods are time-consuming and cumbersome, which limits their effectiveness. </p>

<p>During my internship at Microsoft Reseach, I developed a practical method for food-logging from images. The method utilize a data-base of menu items to estimate the nutritioal content of the querry image.  As demonstrated on a challenging Menu-Match dataset and an existing thirdparty
dataset, our approach outperforms previous computer vision methods. Our Menu-Match dataset of realistic restaurant meals is <a href="http://research.microsoft.com/menumatch/data/">publicly available</a>.

            </div>

            <div class="hr grid_12 clearfix">&nbsp;</div>
            
            <div class="grid_12">
                <a name="hovding"> </a>
                <h4 class="page_title">Building An Invisible Bike Helmet</h4>
                <p><em>Hövding AB, Malmö Sweden</em></p>
                <p>
                <a class="portfolio_item float" href="http://www.hovding.com">
					<span>Invisible Helmet</span>
                    <img src="images/helmet_model.jpg" alt="hövding" width="200" height="300" class="img_right" />
                </a>
                From Hövding's website: Hövding is a bicycle helmet unlike any other currently on the market. It's ergonomic, it's practical, it complies with all the safety requirements, and it's also subtle and blends in with what else you are wearing.Hövding is a collar for bicyclists, worn around the neck. The collar contains a folded up airbag that you'll only see if you happen to have an accident. The airbag is shaped like a hood, surrounding and protecting the bicyclist's head. The trigger mechanism is controlled by sensors which pick up the abnormal movements of a bicyclist in an accident. The actual collar is the visible part of the invention. It's covered by a removable shell that you can change to match your outfit, and we'll be launching new designs all the time. Hövding is a practical accessory that's easy to carry around, it's got a great-looking yet subtle design, and it will save your life. </p>
                
                <p> I was fortunate to be the first employee at Hövding. My task was to develop the accident detection system from scratch. This involved everything from selecting hardware sensors, collecting train data, setting up a computational infrastructure, defining target performances, and developing the actual algorithm. I worked with a small team of engineers on this task. </p>
                
                <p> Hövding has been covered in thousands of video and news-releases, inluding storys from <a href="http://www.nbcnews.com/tech/innovation/invisible-bicycle-helmet-airbag-head-f2D11599972">NBC</a>, <a href="http://www.wired.co.uk/news/archive/2010-10/21/cyclist-collar-airbag-helmet">WIRED</a>,
<a href="http://voices.washingtonpost.com/dr-gridlock/2010/10/airbag_for_cyclists_unveiled.html">The Washington Post</a>, and <a href="http://www.spiegel.de/reise/deutschland/fahrradhelm-so-findet-man-sichere-und-schoene-modelle-a-897161.html">der Spiegel</a>.  Filmmaker Fredrik Gerttens <a href="https://player.vimeo.com/video/43038579">short-film</a> about Hövding have been viewed over 20 million times. Some of my other personal favourites are <a href="https://www.youtube.com/watch?v=TnmJISC1KVw">this story</a> by a Swiss independent reporter, and <a href="http://tvtotal.prosieben.de/tvtotal/videos/player/index.html?contentId=152524&initialTab=related">this one</a> by a German talk show host. Please see <a href="http://www.hovding.com/press/">Hövdings</a> press page for a complete list.
                </p>
            </div>
			<div class="hr grid_12 clearfix">&nbsp;</div>
            
            <div class="grid_12">
                <h4 class="page_title">Blood cell focus</h4>
                <p><em>Cellavision AB, Lund Sweden</em></p>
                <p>
                <a class="portfolio_item float " href="http://www.cellavision.com">
					<span>Mystery blood cells</span>
                    <img src="images/cells.jpg" alt="celsl" width="200" height="200" class="img_right" />
                </a>
                <p>
                From Cellavisions website: CellaVision AB develops and markets products for the health care sector, enabling fast and firm blood cell analysis and quality assurance of morphology diagnosis.
                The company has cutting-edge expertise within sophisticated digital image analysis, artificial intelligence and automated microscopy. For laboratories, this means increased efficiency, a simplification of the procedures and confirmed proficiency.
                The product line includes systems for automatic blood cell differentials and software for differential proficiency testing and education. The products are sold to hospital laboratories and independent commercial laboratories. Today CellaVision is represented in Europe, North America and to some extent in Asia.
                </p>
                
                <p> I did my masters thesis at Cellavision, where I worked on a single-image focus level assessment method for blood cell images. This is in contrast with standard methods for image focusing that use multiple images together to determine focus level. The method I developed has an international patent and is used today at Cellavision. <a href="http://vision.ucsd.edu/sites/default/files/Single%20image%20focus%20level%20assessment%20using%20SVM_1.pdf">[www]</a> </p>
            </div>

                <div class="hr grid_12 clearfix">&nbsp;</div>
                
                <!-- Footer -->
                <p class="grid_12 footer clearfix">
                <span class="float"><b>&copy; Copyright</b> Oscar Beijbom</span>
                <a class="float right" href="#">top</a>
                </p>
                
            </div><!--end wrapper-->
            <script type="text/javascript">
                var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
                document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
                </script>
            <script type="text/javascript">
                try {
                    var pageTracker = _gat._getTracker("UA-6826599-1");
                    pageTracker._trackPageview();
                } catch(err) {}</script>
    </body>
    <!-- HTML/CSS adapted from Aurelius theme by Matt Corner through Catherine Wah-->
</html>
