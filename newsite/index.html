
<head>
<link href='http://fonts.googleapis.com/css?family=Roboto&subset=latin,latin-ext' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="../css/reset.css" />
<link rel="stylesheet" href="beijbom_web.css" />

<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
</head>
<body class="show" id="pages">
<script src="http://code.jquery.com/jquery-1.9.1.js" type="text/javascript"></script>


<div class="center">
	<h1>Oscar Beijbom</h1> 
	<p class="maintext"><a href="mailto:obeijbom@eecs.berkeley.edu">obeijbom@eecs.berkeley.edu</a></p>
	

<p class="maintext">I'm doing a post-doc at the <a href="http://bvlc.eecs.berkeley.edu/">Berkeley Vision and Learning Center</a> on automated quantification of scientific image-data together with <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a> and <a href="http://researchers.uq.edu.au/researcher/839">Ove Hoegh-Guldberg</a>. 
<!--	at the <a href="http://www.gci.uq.edu.au/">Global Change Institute</a> on data analysis for the <a href="http://catlinseaviewsurvey.com/">Catlin Seaview Survey.</a></p> -->


<p class="maintext">I studied computer science at <a href="http://vision.ucsd.edu/">UCSD</a> under <a href="http://cseweb.ucsd.edu/~kriegman/">David Kriegman</a> and <a href="http://vision.cornell.edu/se3/people/serge-belongie/">Serge Belongie</a>, and Engineering Physics at <a href="http://www.lth.se/english/">Lund University</a> under <a href="http://www2.maths.lth.se/vision/">Kalle Åström</a>.


<p class="maintext">I was the lead developer at <a href="http://hovding.com">Hövding</a> where I created the algorithmic framework and hardware design for their <a href="http://techcrunch.com/2012/08/15/invisible-bike-helmet/">invisible bicycle helmet</a>. I have also worked on automated dietary logging systems for consumer applications and focusing algorithms for image-based cell analysis.</p>

<p class="maintext">Lately I have been having tons of fun developing <a href="http://coralnet.ucsd.edu">CoralNet</a>, deploying deep convolutional neural networks to help coral reef ecologists mine their image data.</p> 
 
 
<ul class="social">
<li class="first-item"><a href="#projects">Projects</a></li>
<li><a href="#pubs">Publications</a></li>
<li><a href="#press">Press</a></li>
<li><a href="https://www.linkedin.com/in/oscar-beijbom-696aa6">LinkedIn</a></li>
</ul>


<a class="section-anchor" data-scroll-name="#projects"></a>
<h2>Projects</h2>
<p> Some of my favourite research projects that I have worked on.</p>

	<h3 class="">CoralNet</h3>
		<a name="coralnet"> </a>	
		<a href="http://coralnet.ucsd.edu"><img src="../images/coralnet.jpg" alt="coralnet" width="200" height="200"></a><p>CoralNet is a repository and a resource for benthic images analysis. The site implements our <a href="http://vision.ucsd.edu/sites/default/files/automated_coral_annotation.pdf">method</a> from CVPR2012 and allow researchers, agencies, and private partners to rapidly annotate benthic survey images. The site also serves as a repository and collaboration platform for the scientific community. [<a href="http://coralnet.ucsd.edu">www</a>]</p>

		<p> CoralNet users include the <a href="http://www.catlinseaviewsurvey.com/">Caitlin Seaview Survey</a>, the <a href="http://www.aims.gov.au/">Australian Institute of Marine Science (AIMS) </a>, Washington State University, University of Washington, University of North Carolina, Scripps Institution of Oceanography, Colby College</a>, and <a href="http://stanford.sea.edu/">Stanford@Sea</a>. </p>


	<h3>Cost-Sensitive Multiclass Learning</h3>
		<p><em>UCSD, San Diego, CA, USA</em></p>
		<a href="http://vision.ucsd.edu/sites/default/files/guess_averse.pdf"><img src="../images/guess_averse.jpg" alt="guess_averse" width="200" height="200"></a><p> Supervised machine learning algorithms are commonly studied cost-balanced binary classification. In such scenario the algorithm learns to seperate between two equally costly (important) classes. However, in many practial sitautions, there are multiple classes, and in addition, misclassification costs may vary between the classes. This leads to the more complicated scenario of cost-sensitive multiclass learning. </p>

		<p>In joint work with Steve Branson, we proposed a fast <a href="http://vision.ucsd.edu/sites/default/files/cvpr2013_efficient_0.pdf">structured Support Vector Machine (SVM) solver</a> capable of cost-sensitive multiclass learning. The solver is based on coordinate dual ascent and converges order of magnitudes faster than previous structured SVM solvers. In another paper I examined properties of loss functions for cost-sensitive multiclass learning together with Mohammad Saberian, and showed that a property, which we call <a href="http://vision.ucsd.edu/sites/default/files/guess_averse.pdf">guess-averse</a> has strong empirical imporatance.</p>


	<h3>Counting Calories</h3>
		<p><em>Microsoft Research, Seattle, Washington, USA</em></p>
    	<p><a href="http://research.microsoft.com/menumatch/data/"> <img src="../images/menu-match.jpg" alt="menu-match" width="200" height="150"></a>The World Health Organization (WHO) predicts that overweight and obesity may soon replace more traditional public health concerns such as undernutrition and infectious diseases as the most significant cause of poor health. Logging food and calorie intake has been shown to facilitate weight management, but current food logging methods are time-consuming and cumbersome, which limits their effectiveness. </p>

		<p>During my internship at Microsoft Reseach, I developed a practical method for food-logging from images. The method utilize a data-base of menu items to estimate the nutritioal content of the querry image.  As demonstrated on a challenging Menu-Match dataset and an existing thirdparty dataset, our approach outperforms previous computer vision methods. Our Menu-Match dataset of realistic restaurant meals is <a href="http://research.microsoft.com/menumatch/data/">publicly available</a>.

	
    <h3>Building An Invisible Bike Helmet</h3>
    	<a name="hovding"> </a>
    	<p><em>Hövding AB, Malmö Sweden</em></p>
    	<p><a href="http://www.hovding.com"><img src="../images/helmet_model.jpg" alt="hövding" width="200" height="300"></a> From Hövding's website: <em>"Hövding is a bicycle helmet unlike any other currently on the market. It's ergonomic, it's practical, it complies with all the safety requirements, and it's also subtle and blends in with what else you are wearing. Hövding is a collar for bicyclists, worn around the neck. The collar contains a folded up airbag that you'll only see if you happen to have an accident. The airbag is shaped like a hood, surrounding and protecting the bicyclist's head. The trigger mechanism is controlled by sensors which pick up the abnormal movements of a bicyclist in an accident. Hövding is a practical accessory that's easy to carry around, it's got a great-looking yet subtle design, and it will save your life."</em> </p>
                
    	<p> I was fortunate to be the first employee at Hövding. My task was to develop the accident detection system from scratch. This involved everything from selecting hardware sensors, collecting train data, setting up a computational infrastructure, defining target performances, and developing the actual algorithm. I worked with a small team of engineers on this task. </p>
                
    	<p> Hövding has been covered in thousands of video and news-releases, inluding storys from <a href="http://www.nbcnews.com/tech/innovation/invisible-bicycle-helmet-airbag-head-f2D11599972">NBC</a>, <a href="http://www.wired.co.uk/news/archive/2010-10/21/cyclist-collar-airbag-helmet">WIRED</a>,
		<a href="http://voices.washingtonpost.com/dr-gridlock/2010/10/airbag_for_cyclists_unveiled.html">The Washington Post</a>, and <a href="http://www.spiegel.de/reise/deutschland/fahrradhelm-so-findet-man-sichere-und-schoene-modelle-a-897161.html">der Spiegel</a>.  Filmmaker Fredrik Gerttens <a href="https://player.vimeo.com/video/43038579">short-film</a> about Hövding have been viewed over 20 million times. Some of my other personal favourites are <a href="https://www.youtube.com/watch?v=TnmJISC1KVw">this story</a> by a Swiss independent reporter, and <a href="http://tvtotal.prosieben.de/tvtotal/videos/player/index.html?contentId=152524&initialTab=related">this one</a> by a German talk show host. Please see <a href="http://www.hovding.com/press/">Hövdings</a> press page for a complete list.</p>


	<h3>Blood cell focus</h3>
    	<p><em>Cellavision AB, Lund Sweden</em></p>
        <p><a href="http://www.cellavision.com"><img src="./../images/cells.jpg" alt="celsl" width="200" height="200"></a>From Cellavisions website: <em>"CellaVision develops and markets products for the health care sector, enabling fast and firm blood cell analysis and quality assurance of morphology diagnosis. The company has cutting-edge expertise within sophisticated digital image analysis, artificial intelligence and automated microscopy. For laboratories, this means increased efficiency, a simplification of the procedures and confirmed proficiency. The product line includes systems for automatic blood cell differentials and software for differential proficiency testing and education. The products are sold to hospitals and laboratories in Europe, North America and Asia."</em> </p>
                
        <p> I did my masters thesis at Cellavision, where I worked on a single-image focus level assessment method for blood cell images. This is in contrast with standard methods for image focusing that use multiple images together to determine focus level. The method I developed has an <a href="http://www.google.com/patents/US20100177187">international patent</a> and is currently deployed. </p>
           



</div>


<div class="center">

<a class="section-anchor" data-scroll-name="#pubs"></a>
<h2>Selected publications</h2>
<p> Full list of publications is availible at <a href="http://scholar.google.com/citations?user=XP_Hxm4AAAAJ&hl=en">Google Scholar profile</a></p>
<ul>
	<li>O. Beijbom et al. <i>"Towards automated annotation of benthic survey images: Variability of human experts and operational modes of automation"</i>. PLoS One, 2015.
		[<a href="https://www.dropbox.com/s/upy5kkl4qxla036/ios_plos2015.pdf?dl=1"]>pdf</a>]
		[<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130312">www</a>]
		[<a href="http://datadryad.org/resource/doi:10.5061/dryad.m5pr3">data</a>]
	</li>	

    <li >O. Beijbom, N. Joshi, D. Morris, S. Saponas, S. Khullar. <i>"Menu-Match: Restuarant-Specific Food Logging from Images"</i>. Winter Conference on Applications of Computer Vision (WACV), 2015. 
		[<a href="https://www.dropbox.com/s/xk4tq94r9r3c2zm/menu-match.pdf?dl=0">paper</a>]
		[<a href="http://research.microsoft.com/menumatch/data/">data</a>]
		[<a href="http://research.microsoft.com/menumatch/">www</a>]
	</li>

	<li >O. Beijbom<sup>*</sup>, M. Saberian<sup>*</sup>, N. Vasconcelos, D. Kriegman. <i>"Guess Averse Loss Functions for Cost-Sensitive Multiclass Boosting"</i>. International Conference on Machine Learning (ICML), Beijing, June 2014. <sup>*</sup>equal contribution. 
		[<a href="http://vision.ucsd.edu/sites/default/files/guess_averse.pdf">paper</a>] 
        [<a href="http://vision.ucsd.edu/sites/default/files/guess_averse_supplementary_0.pdf">supp. info</a>] 
        [<a href="https://www.dropbox.com/s/v5q7rrbwf4bc50i/guess_averse_icml_talk_beijbom.pptx">talk (ppt)</a>]
        [<a href="http://techtalks.tv/talks/guess-averse-loss-functions-for-cost-sensitive-multiclass-boosting/60880/">talk (video)</a>] 
        [<a href="https://www.dropbox.com/s/liv681yzcaw5hnb/guess_averse_poster.pptx">poster</a>] 
        [<a href="http://vision.ucsd.edu/~beijbom/files/ICML_2014_guess_averse_code_data.zip">code</a>]
    </li>

    <li >S. Branson, O. Beijbom, S. Belongie. <i> "Efficient Large-Scale Structured Learning"</i>. IEEE Conference on Computer Vision (CVPR), Portland, Oregon, June 2013.
		[<a href="http://vision.ucsd.edu/sites/default/files/cvpr2013_efficient_0.pdf">paper</a>]
		[<a href="http://vision.caltech.edu/~sbranson/files/branson2013efficient.pptx">talk (ppt)</a>]
		[<a href="http://techtalks.tv/talks/efficient-large-scale-structured-learning/58645/">talk (video)</a>]
		[<a href="http://vision.caltech.edu/~sbranson/code/index.html#learning">code</a>]
	</li>

	<li >O. Beijbom, P.J.Edmunds, D.I.Kline, B.G.Mitchell, D.Kriegman. <i>"Automated Annotation of Coral Reef Survey Images"</i>. IEEE Conference on Computer Vision (CVPR), Providence, Rhode Island, June 2012.
		[<a href="http://vision.ucsd.edu/sites/default/files/automated_coral_annotation.pdf">paper</a>]
		[<a href="http://vision.ucsd.edu/content/moorea-labeled-corals">data</a>]
	</li>
</ul>  

</div>


<div class="center">

<a class="section-anchor" data-scroll-name="#press"></a>
<h2>Press</h2>
<ul >
	<li >Mar 2015: Deborah Osae-Oppong highlights our <a href="http://www.jacobsschool.ucsd.edu/re/">UCSD research expo</a> poster on the UCSD Jacobs School of Engineering blog. [<a href = "http://jacobsschoolofengineering.blogspot.com/2015/03/meet-engineers-of-tomorrow-oscar-beijbom.html">www</a>]</li>
	
	<li >Nov 2014: Jonathan Cohen at <a href="http://www.nvidia.com/content/global/global.php">NVIDIA</a> highlights <a href="projects.html#coralnet">CoralNet</a> in his talk at the SuperComputer conference. CoralNet section starts at 9.30. [<a href="http://on-demand.gputechconf.com/supercomputing/2014/video/SC411-machine-learning-computational-researchers.html">www</a>]</li>

	<li >May 2014: Destin at <a href="https://www.youtube.com/user/destinws2">SmarterEveryDay</a> follows the data collected by the <a href="http://catlinseaviewsurvey.com/">Catlin Seaview Survey</a> all the way to <a href="projects.html#coralnet">CoralNet</a>. [<a href="https://www.youtube.com/watch?v=az1PTIehYKI">www</a>]</li> 
			
	<li >November 2013: NBCnews does a nice story on <a href="projects.html#hovding">Hövding</a>. [<a href="http://www.nbcnews.com/tech/innovation/invisible-bicycle-helmet-airbag-head-f2D11599972">www</a>]</li> 			
			
	<li >September 2013: Greenwire covers <a href="projects.html#coralnet">CoralNet</a>. [<a href="http://www.eenews.net/greenwire/stories/1059986651">www</a>]</li>

	<li >April 2012: German TV talkshow host tries to outsmart the accident detection system of <a href="projects.html#hovding">Hövding</a>. Highlights: 05:45 Stunt man stages an accident and Hövding inflates. 07:10 TV-host tries to inflate Hövding when not having an accident
08:00 TV-host goes crazy trying to trick Hövding. [<a href="http://tvtotal.prosieben.de/tvtotal/videos/player/index.html?contentId=152524&initialTab=related">www</a>]</li> 
	
	<li >May 2012: Fredrik Gerttens creates a short-film about the founders of <a href="projects.html#hovding">Hövding</a>. [<a href="https://player.vimeo.com/video/43038579">www</a>]</li> 
</ul>
</div>




<script type="text/javascript">
$("a[href^='#']").click(function(){
	var clicked = $(this).attr("href");
	var link = $('a[data-scroll-name="' + clicked + '"]');
	
	$(".selected").attr("class","");
	
	$('body,html').animate({
		'scrollTop':   $(link).offset().top
	}, 1000, function() {
    // Animation complete.
	});
	$(this).attr("class"," selected");
});
</script>

</body>
</html>
